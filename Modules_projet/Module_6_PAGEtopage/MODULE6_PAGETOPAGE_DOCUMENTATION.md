# ğŸ“¦ MODULE 6 - PAGEtopage : Enrichissement Linguistique

**Documentation de l'outil d'enrichissement linguistique**

---

## ğŸ“‹ Vue d'ensemble

MODULE 6 est un pipeline Python d'enrichissement linguistique pour les textes latins et franÃ§ais issus de manuscrits et Ã©ditions **gÃ©nÃ©riques** (hors DÃ©cret de Gratien).

**Nom de l'outil** : PAGEtopage
**Langage** : Python 3.10+
**EntrÃ©e** : Fichiers XML PAGE (sortie du Module 5)
**Sortie** : Corpus enrichi avec lemmatisation + formats exploitables

âš ï¸ **IMPORTANT** : Ce module est utilisÃ© pour le **cas gÃ©nÃ©ral uniquement**. Le DÃ©cret de Gratien suit un pipeline spÃ©cifique et n'utilise PAS PAGEtopage.

---

## ğŸ”„ Pipeline en 4 Ã©tapes (3 + correction optionnelle)

### **Ã‰TAPE 1 : EXTRACTION**

**Objectif** : Extraire le texte des fichiers XML PAGE

**Processus** :
1. Lecture des XML PAGE
2. DÃ©tection du mode colonnes :
   - **Single column** : Extraction sÃ©quentielle (manuscrits simples)
   - **Dual columns** : Extraction en 2 colonnes (Ã©ditions en colonnes)
3. **Fusion des mots coupÃ©s** : Reconstitution des mots avec trait d'union
   - Exemple : `re-` + `constituer` â†’ `reconstituer`
4. GÃ©nÃ©ration d'un fichier JSON intermÃ©diaire

**Technologies** :
- `lxml` : Manipulation XML
- Algorithme de fusion de cÃ©sure

**Sortie** : `extracted.json`

---

### **Ã‰TAPE 2 : ENRICHISSEMENT**

**Objectif** : Ajouter annotations linguistiques (lemmes, POS tags)

**Processus** :
1. Chargement du JSON extrait
2. **DÃ©coupage en phrases** : DÃ©tection des limites de phrases
3. **Tokenisation** : SÃ©paration en mots individuels
4. **Traitement TreeTagger** : Lemmatisation + POS-tagging
   - TreeTagger = Outil rapide et fiable pour le latin
   - **Installation automatique** lors de la premiÃ¨re utilisation (~20 Mo)
   - Supporte Latin et FranÃ§ais
5. GÃ©nÃ©ration du format **vertical** : 1 mot par ligne avec annotations

**Format vertical** :
```
Mot      POS    Lemme
---      ---    -----
In       PRP    in
nomine   NOM    nomen
Patris   NOM    pater
```

**Technologies** :
- TreeTagger : Lemmatisation latin/franÃ§ais (auto-installÃ©)
- Algorithmes de segmentation de phrases
- Tokenisation adaptÃ©e au latin mÃ©diÃ©val

**Sortie** : `corpus.vertical.txt`

âš ï¸ **Note** : TreeTagger s'installe automatiquement lors de la premiÃ¨re utilisation (~1 minute pour 350 pages ensuite).

---

### **Ã‰TAPE 3 : EXPORT**

**Objectif** : GÃ©nÃ©rer les fichiers exploitables dans diffÃ©rents formats

**4 formats disponibles** :

1. **Scholarly** (recommandÃ©) : Format acadÃ©mique avec en-tÃªte complet
   - En-tÃªte dÃ©taillÃ© avec toutes les mÃ©tadonnÃ©es
   - Texte en lignes continues
   - Pour publications et rÃ©-enrichissement
   - PrÃ©serve parfaitement les mÃ©tadonnÃ©es

2. **Clean** : Texte brut lisible
   - Pour lecture humaine
   - Pas d'annotations visibles
   - Texte fluide

3. **Diplomatic** : Avec annotations inline
   - Annotations semi-visibles
   - Conserve structure originale
   - Pour Ã©dition critique

4. **Annotated** : Format tabulaire complet
   - Toutes les annotations
   - Format machine-readable
   - Pour analyse linguistique

**Processus** :
1. Lecture du corpus vertical
2. Choix du format de sortie
3. **SÃ©paration par pages** : Un fichier par page
4. GÃ©nÃ©ration des fichiers complÃ©mentaires :
   - `texte_complet.txt` : Fichier unique avec tout le texte
   - `pages_index.json` : Index des pages avec mÃ©tadonnÃ©es
   - `corpus_stats.json` : Statistiques du corpus
   - `images_mapping.txt` : Correspondance texte â†” images

**MÃ©tadonnÃ©es incluses** :
Les mÃ©tadonnÃ©es proviennent de **Heurist** et sont renseignÃ©es dans `config.yaml` :
```yaml
edition_id: "Edi-7"
title: "Magistri Honorii Summa ''De iure canonico tractaturus''"
language: "Latin"
author: "Honorius"
source: "Summa ''De iure canonico tractaturus''"
type: "Droit canonique"
date: "1188"
lieu: "France"
ville: "Paris"
```

**Sortie** : Dossier avec tous les fichiers + mÃ©tadonnÃ©es enrichies

---

### **Ã‰TAPE 4 : RÃ‰-ENRICHISSEMENT (Optionnel)**

**Objectif** : Corriger manuellement le texte et regÃ©nÃ©rer le corpus vertical

âš ï¸ **Note** : Cette Ã©tape est **optionnelle** et ne s'utilise que si vous devez corriger des coquilles ou erreurs OCR dans le texte final.

**Cas d'usage** :
- Corriger des erreurs OCR/HTR
- Fixer des fautes de transcription
- AmÃ©liorer la qualitÃ© du texte final
- RÃ©gÃ©nÃ©rer le corpus vertical avec les corrections

**Processus** :
1. **Correction manuelle** : Ã‰dition des fichiers texte (format scholarly)
   - Ouvrir les fichiers dans un Ã©diteur de texte
   - Corriger les coquilles, erreurs OCR, etc.
   - Sauvegarder les fichiers corrigÃ©s
2. **Parse format scholarly** : Extraction du texte et des mÃ©tadonnÃ©es
   - Lecture des en-tÃªtes dÃ©taillÃ©s
   - PrÃ©servation de toutes les mÃ©tadonnÃ©es
3. **Re-tokenisation** : Nouveau dÃ©coupage en mots
4. **Re-lemmatisation** : TreeTagger sur le texte corrigÃ©
   - RÃ©gÃ©nÃ©ration des lemmes et POS tags
5. GÃ©nÃ©ration du nouveau corpus vertical avec corrections

**Technologies** :
- Parser scholarly : Extraction texte + mÃ©tadonnÃ©es
- TreeTagger : Re-lemmatisation automatique
- PrÃ©servation intÃ©grale des mÃ©tadonnÃ©es

**Sortie** : `corpus_corrige.vertical.txt`

**Avantages** :
- Permet de corriger facilement dans des fichiers texte lisibles
- RÃ©gÃ©nÃ¨re automatiquement les annotations linguistiques
- PrÃ©serve toutes les mÃ©tadonnÃ©es du corpus
- Pas besoin de revenir aux XML sources

---

## ğŸ’» Utilisation

### Installation

```bash
# PrÃ©requis
Python 3.10 ou supÃ©rieur

# DÃ©pendances
pip install pyyaml treetaggerwrapper

# TreeTagger s'installe automatiquement
# Pas de configuration manuelle nÃ©cessaire
```

### Configuration

1. **CrÃ©er le fichier config.yaml**
   ```bash
   python -m PAGEtopage init
   ```

2. **Ã‰diter config.yaml**
   - Consulter Heurist pour rÃ©cupÃ©rer les mÃ©tadonnÃ©es
   - Copier les mÃ©tadonnÃ©es dans le fichier config.yaml
   - Configurer les chemins d'entrÃ©e/sortie
   - Choisir le mode colonnes (single/dual)
   - Choisir le format de sortie (clean/diplomatic/annotated)

### Commandes CLI

```bash
# Pipeline complet (3 Ã©tapes obligatoires)
python -m PAGEtopage run --input ./xml_pages/ --output ./output/ --config config.yaml

# Ã‰tape 1 seule (extraction)
python -m PAGEtopage extract --input ./xml_pages/ --output ./extracted.json

# Ã‰tape 2 seule (enrichissement)
python -m PAGEtopage enrich --input ./extracted.json --output ./corpus.vertical.txt

# Ã‰tape 3 seule (export)
python -m PAGEtopage export --input ./corpus.vertical.txt --output ./pages/ --format scholarly

# Ã‰tape 4 (optionnelle) : rÃ©-enrichissement aprÃ¨s correction
python -m PAGEtopage re-enrich --input ./pages_corrigees/ --output ./corpus_corrige.vertical.txt --config config.yaml
```

---

## ğŸ”— Lien avec les autres modules

### En amont : MODULE 5 (Nettoyage)

**EntrÃ©e de PAGEtopage** : Fichiers XML PAGE finalisÃ©s

Le Module 5 gÃ©nÃ¨re les XML PAGE nettoyÃ©s qui servent d'entrÃ©e Ã  PAGEtopage.

### En parallÃ¨le : Base Heurist

**Source des mÃ©tadonnÃ©es** :

1. Les fiches de mÃ©tadonnÃ©es sont extraites et stockÃ©es dans Heurist
2. L'utilisateur consulte Heurist pour l'Ã©dition/manuscrit Ã  traiter
3. Copie des mÃ©tadonnÃ©es pertinentes dans `config.yaml`
4. PAGEtopage utilise ces mÃ©tadonnÃ©es pour enrichir les exports

**MÃ©tadonnÃ©es utilisÃ©es** :
- `edition_id` : Identifiant Heurist (ex: "Edi-7")
- `title` : Titre complet
- `language` : Latin / FranÃ§ais
- `author` : Auteur(s)
- `source` : Oeuvre source
- `type` : Type de droit (canonique, romain, etc.)
- `date` : Date de rÃ©daction
- `lieu` : Lieu de rÃ©daction
- `ville` : Ville spÃ©cifique

### En aval : NoSketch-Engine

**Sortie vers NoSketch** :

Les fichiers verticaux gÃ©nÃ©rÃ©s par PAGEtopage sont ensuite :
1. FusionnÃ©s avec `Fusion_txt_NoSketch.py`
2. ImportÃ©s dans NoSketch-Engine pour consultation

---

## ğŸ¯ Cas d'usage

### âœ… Utilisations appropriÃ©es

- Manuscrits juridiques gÃ©nÃ©raux
- Ã‰ditions imprimÃ©es
- Textes latins classiques
- Textes franÃ§ais mÃ©diÃ©vaux
- Corpus nÃ©cessitant lemmatisation

### âŒ Exclusions

- **DÃ©cret de Gratien** : Utilise son propre pipeline spÃ©cifique
  - Raison : Structure particuliÃ¨re (allÃ©gations + canons)
  - Traitement spÃ©cifique dÃ©jÃ  implÃ©mentÃ©
  - Format .txt adaptÃ© dÃ©jÃ  sur NoSketch

---

## ğŸ“Š Performances et statistiques

**Vitesse de traitement** : ~1 minute pour 350 pages (aprÃ¨s installation de TreeTagger)

**Taux d'automatisation** : ~100%
- Extraction : 100% automatique
- Enrichissement : 100% automatique (TreeTagger auto-installÃ©)
- Export : 100% automatique
- RÃ©-enrichissement : 100% automatique (aprÃ¨s corrections manuelles)

**QualitÃ© de lemmatisation** :
- Latin : Excellente (TreeTagger optimisÃ©)
- FranÃ§ais : TrÃ¨s bonne
- Installation automatique : Aucune configuration manuelle

---

## ğŸ› ï¸ Technologies utilisÃ©es

**Langage** : Python 3.10+

**BibliothÃ¨ques principales** :
- **TreeTagger** : Lemmatisation latin (installation automatique)
- **treetaggerwrapper** : Interface Python pour TreeTagger
- **PyYAML** : Configuration
- **lxml** : Manipulation XML
- **JSON** : Formats intermÃ©diaires
- **Argparse** : Interface CLI

**Outils connexes** :
- Heurist : Source des mÃ©tadonnÃ©es
- Fusion_txt_NoSketch.py : Export vers NoSketch

---

## ğŸ“ Structure du code

```
PAGEtopage/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ __main__.py              # Point d'entrÃ©e CLI
â”œâ”€â”€ cli.py                   # Interface ligne de commande
â”œâ”€â”€ config.py                # Gestion configuration
â”œâ”€â”€ config_example.yaml      # Exemple de configuration
â”œâ”€â”€ models.py                # ModÃ¨les de donnÃ©es
â”‚
â”œâ”€â”€ step1_extract/           # Ã‰TAPE 1
â”‚   â”œâ”€â”€ extractor.py         # Extraction XML â†’ JSON
â”‚   â”œâ”€â”€ hyphen_merger.py     # Fusion mots coupÃ©s
â”‚   â””â”€â”€ zone_parser.py       # Analyse zones XML
â”‚
â”œâ”€â”€ step2_enrich/            # Ã‰TAPE 2
â”‚   â”œâ”€â”€ processor.py         # Orchestration enrichissement
â”‚   â”œâ”€â”€ tokenizer.py         # Tokenisation
â”‚   â”œâ”€â”€ lemmatizer.py        # Lemmatisation TreeTagger
â”‚   â””â”€â”€ treetagger_installer.py  # Installation auto TreeTagger
â”‚
â”œâ”€â”€ step3_export/            # Ã‰TAPE 3
â”‚   â”œâ”€â”€ exporter.py          # Export principal
â”‚   â”œâ”€â”€ formatters.py        # 4 formats (scholarly/clean/diplomatic/annotated)
â”‚   â”œâ”€â”€ scholarly_parser.py  # Parser format scholarly
â”‚   â”œâ”€â”€ index_generator.py   # GÃ©nÃ©ration index + stats
â”‚   â””â”€â”€ vertical_parser.py   # Lecture format vertical
â”‚
â”œâ”€â”€ step4_reenrich/          # Ã‰TAPE 4 (optionnelle)
â”‚   â””â”€â”€ reenricher.py        # RÃ©-enrichissement aprÃ¨s correction
â”‚
â””â”€â”€ tests/                   # Tests unitaires
    â”œâ”€â”€ test_step1_extract.py
    â”œâ”€â”€ test_step2_enrich.py
    â””â”€â”€ test_step3_export.py
```

---

## ğŸ“ Exemples de configuration

### Manuscrit simple (1 colonne)

```yaml
# config.yaml
metadata:
  edition_id: "Edi-12"
  title: "Summa Decretorum"
  language: "Latin"
  author: "Gratianus"
  type: "Droit canonique"
  date: "1140"

input:
  xml_directory: "/path/to/xml_pages/"

processing:
  column_mode: "single"  # 1 colonne
  merge_hyphens: true

output:
  format: "clean"        # Texte lisible
  output_directory: "/path/to/output/"
  split_pages: true
```

### Ã‰dition imprimÃ©e (2 colonnes)

```yaml
# config.yaml
metadata:
  edition_id: "Edi-7"
  title: "Magistri Honorii Summa"
  language: "Latin"
  author: "Honorius"
  type: "Droit canonique"
  date: "1188"
  lieu: "France"
  ville: "Paris"

input:
  xml_directory: "/path/to/xml_pages/"

processing:
  column_mode: "dual"      # 2 colonnes
  merge_hyphens: true

output:
  format: "diplomatic"     # Avec annotations
  output_directory: "/path/to/output/"
  split_pages: true
```

---

## âš ï¸ Points d'attention

### PremiÃ¨re exÃ©cution

TreeTagger s'installe automatiquement lors de la premiÃ¨re utilisation (~20 Mo). Les exÃ©cutions suivantes sont rapides (~1 minute pour 350 pages).

### QualitÃ© des donnÃ©es d'entrÃ©e

PAGEtopage suppose que les XML PAGE sont dÃ©jÃ  :
- NettoyÃ©s (Module 5)
- Bien structurÃ©s
- Avec balises correctes

Si donnÃ©es d'entrÃ©e corrompues â†’ rÃ©sultats imprÃ©visibles.

### MÃ©tadonnÃ©es manuelles

Les mÃ©tadonnÃ©es doivent Ãªtre **copiÃ©es manuellement** depuis Heurist dans config.yaml. VÃ©rifier :
- L'ID d'Ã©dition correct (ex: "Edi-7")
- L'orthographe des noms
- Les dates au bon format

---

## ğŸ”„ Workflow complet

```
1. Module 5 â†’ XML PAGE nettoyÃ©s
        â†“
2. Consultation Heurist â†’ RÃ©cupÃ©ration mÃ©tadonnÃ©es
        â†“
3. Ã‰dition config.yaml â†’ Ajout mÃ©tadonnÃ©es
        â†“
4. PAGEtopage Ã‰TAPE 1 â†’ Extraction texte
        â†“
5. PAGEtopage Ã‰TAPE 2 â†’ Enrichissement TreeTagger
        â†“
6. PAGEtopage Ã‰TAPE 3 â†’ Export multi-formats (scholarly recommandÃ©)
        â†“
7. (Optionnel) Correction manuelle â†’ Ã‰dition des fichiers texte
        â†“
8. (Optionnel) PAGEtopage Ã‰TAPE 4 â†’ RÃ©-enrichissement
        â†“
9. Fusion_txt_NoSketch.py â†’ PrÃ©paration NoSketch
        â†“
10. Import NoSketch-Engine â†’ Consultation finale
```

---

## ğŸ“š Documentation complÃ©mentaire

**Fichiers du projet** :
- `PAGEtopage/README.md` : Documentation technique complÃ¨te
- `PAGEtopage/QUICKSTART.md` : Guide de dÃ©marrage rapide
- `DOCUMENTATION_PAGETOPAGE_SCHEMA.md` : Liens avec schÃ©mas

**SchÃ©mas** :
- `Shema_module_projet/flowchart-module6-pagetopage.mmd` : Pipeline dÃ©taillÃ©

---

## âœ… Ã‰tat actuel

**MODULE 6 (PAGEtopage)** : ğŸ”„ **En cours de dÃ©veloppement**

- Code source complet : âœ…
- Tests unitaires : âœ…
- Documentation : âœ…
- Configuration YAML : âœ…
- Interface CLI : âœ…

**PrÃªt pour utilisation** avec configuration appropriÃ©e.

---

## ğŸš€ Prochaines Ã©tapes

1. Finaliser les tests sur corpus rÃ©el
2. Optimisation des performances
3. Documentation utilisateur dÃ©taillÃ©e
4. IntÃ©gration complÃ¨te dans le pipeline global
