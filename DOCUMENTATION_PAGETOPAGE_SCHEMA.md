# Documentation PAGEtopage - Liaison avec les SchÃ©mas du Pipeline

## ğŸ“‹ Vue d'ensemble

Ce document Ã©tablit le lien entre le **dossier PAGEtopage** (nouveau module de traitement) et les **schÃ©mas du pipeline** existants dans `Shema_module_projet/`.

**PAGEtopage** reprÃ©sente une **extension majeure du Module 5**, ajoutant des capacitÃ©s d'enrichissement linguistique et d'export en formats exploitables pour l'analyse textuelle.

---

## ğŸ”— Position de PAGEtopage dans le Pipeline Global

### Pipeline Complet (Modules 1-5 + PAGEtopage)

```
MODULE 1: Acquisition Manuscrits
    â†“
MODULE 2: TÃ©lÃ©chargement Images
    â†“
MODULE 3: Acquisition Ã‰ditions
    â†“
MODULE 4: Traitement eScriptorium (HTR/OCR)
    â†“
MODULE 5: Nettoyage Post-eScriptorium â† SchÃ©ma existant
    â†“
ğŸ“¦ PAGEtopage: Enrichissement Linguistique â† NOUVEAU
    â†“
FORMAT VERTICAL + CORPUS ANNOTÃ‰
```

---

## ğŸ“Š Correspondance Module 5 â†” PAGEtopage

### Ce que fait le Module 5 (selon flowchart-module5.mmd)

| Ã‰tape Module 5 | Description | SchÃ©ma |
|----------------|-------------|---------|
| ğŸ”¹ Import XML | Import depuis eScriptorium | `flowchart-module5.mmd:11-13` |
| ğŸ”¹ Stockage Seafile | Archivage cloud avec ID | `flowchart-module5.mmd:12` |
| ğŸ”¹ Distinction Layout | 1, 2 ou 4 rÃ©gions Main | `flowchart-module5.mmd:22-24` |
| ğŸ”¹ Regex Communes | Normalisation espaces, ponctuation | `flowchart-module5.mmd:105-110` |
| ğŸ”¹ Regex SpÃ©cifiques | AbbrÃ©viations, numÃ©rotation | `flowchart-module5.mmd:112-118` |
| ğŸ”¹ VÃ©rification | DÃ©tection erreurs, cohÃ©rence | `flowchart-module5.mmd:81-94` |
| âœ… **Sortie** | **Transcriptions XML PAGE finalisÃ©es** | `flowchart-module5.mmd:95` |

### Ce que fait PAGEtopage (au-delÃ  du Module 5)

| Ã‰tape PAGEtopage | Description | Fichier Code |
|------------------|-------------|--------------|
| ğŸ”¹ **ENTRÃ‰E** | **XML PAGE finalisÃ©s (sortie Module 5)** | - |
| ğŸ”¹ Extraction (Step 1) | Extraction texte, fusion mots coupÃ©s | `PAGEtopage/step1_extract/` |
| ğŸ”¹ Enrichissement (Step 2) | Lemmatisation, POS-tagging (CLTK) | `PAGEtopage/step2_enrich/` |
| ğŸ”¹ Export (Step 3) | Format vertical, fichiers texte | `PAGEtopage/step3_export/` |
| âœ… **SORTIE** | **Corpus annotÃ© + Fichiers texte exploitables** | - |

---

## ğŸ¯ PAGEtopage = Module 5.5 ou Module 6 ?

### Option 1 : Module 5 Ã‰tendu (5.5)
PAGEtopage peut Ãªtre considÃ©rÃ© comme une **extension du Module 5**, ajoutant :
- Post-traitement linguistique
- Enrichissement automatique
- Transformation en formats d'analyse

### Option 2 : Nouveau Module 6
PAGEtopage pourrait Ãªtre un **Module 6 distinct** :
- **MODULE 5** : Nettoyage et finalisation des XML PAGE
- **MODULE 6** : Transformation linguistique et enrichissement

**â¡ï¸ Recommandation** : ConsidÃ©rer PAGEtopage comme **Module 6 - Enrichissement Linguistique**

---

## ğŸ“ Nouveau SchÃ©ma ProposÃ© : Module 6 (PAGEtopage)

### Diagramme de Flux Module 6

```mermaid
flowchart TD
    %% ========================================
    %% MODULE 6 - ENRICHISSEMENT LINGUISTIQUE (PAGEtopage)
    %% ========================================

    START([ğŸ“¦ MODULE 6<br/>PAGEtopage - Enrichissement Linguistique])

    %% ENTRÃ‰E
    INPUT_MODULE5[ğŸ“¥ XML PAGE finalisÃ©s<br/>Sortie du Module 5]
    START --> INPUT_MODULE5

    %% ========================================
    %% Ã‰TAPE 1 : EXTRACTION
    %% ========================================
    subgraph STEP1 [ğŸ“„ Ã‰TAPE 1 : Extraction]
        EXTRACT_START[ğŸ” Lecture des XML PAGE<br/>Analyse de la structure]

        COLUMN_DECISION{Mode colonnes ?}
        SINGLE_COL[ğŸ“„ Single Column<br/>Extraction sÃ©quentielle]
        DUAL_COL[ğŸ“„ğŸ“„ Dual Columns<br/>Extraction en 2 colonnes]

        HYPHEN_MERGE[ğŸ”— Fusion mots coupÃ©s<br/>re-/constituer â†’ reconstituer]

        JSON_INTERMEDIATE[ğŸ’¾ Fichier JSON intermÃ©diaire<br/>extracted.json]

        EXTRACT_START --> COLUMN_DECISION
        COLUMN_DECISION -->|single| SINGLE_COL
        COLUMN_DECISION -->|dual| DUAL_COL
        SINGLE_COL --> HYPHEN_MERGE
        DUAL_COL --> HYPHEN_MERGE
        HYPHEN_MERGE --> JSON_INTERMEDIATE
    end

    INPUT_MODULE5 --> EXTRACT_START

    %% ========================================
    %% Ã‰TAPE 2 : ENRICHISSEMENT
    %% ========================================
    subgraph STEP2 [ğŸ“ Ã‰TAPE 2 : Enrichissement]
        ENRICH_START[ğŸ“– Lecture JSON<br/>Chargement corpus]

        SENTENCE_SPLIT[âœ‚ï¸ DÃ©coupage en phrases<br/>DÃ©tection de limites]

        TOKENIZATION[ğŸ”¤ Tokenisation<br/>SÃ©paration en mots]

        CLTK_PROCESS[ğŸ§  Traitement CLTK<br/>Lemmatisation + POS-tagging]

        VERTICAL_FORMAT[ğŸ“Š Format Vertical<br/>Mot | POS | Lemme]

        CORPUS_VERTICAL[ğŸ’¾ corpus.vertical.txt<br/>Fichier annotÃ© complet]

        ENRICH_START --> SENTENCE_SPLIT
        SENTENCE_SPLIT --> TOKENIZATION
        TOKENIZATION --> CLTK_PROCESS
        CLTK_PROCESS --> VERTICAL_FORMAT
        VERTICAL_FORMAT --> CORPUS_VERTICAL
    end

    JSON_INTERMEDIATE --> ENRICH_START

    %% ========================================
    %% Ã‰TAPE 3 : EXPORT
    %% ========================================
    subgraph STEP3 [ğŸ“¤ Ã‰TAPE 3 : Export]
        EXPORT_START[ğŸ“– Lecture corpus vertical]

        FORMAT_CHOICE{Format de sortie ?}

        FORMAT_CLEAN[âœ¨ Clean<br/>Texte brut lisible]
        FORMAT_DIPLO[ğŸ“ Diplomatic<br/>Avec annotations inline]
        FORMAT_ANNOT[ğŸ“Š Annotated<br/>Format tabulaire]

        PAGE_SPLIT[ğŸ“‘ SÃ©paration par pages<br/>Un fichier par page]

        COMBINED_FILE[ğŸ“˜ Fichier texte complet<br/>texte_complet.txt]

        INDEX_JSON[ğŸ—‚ï¸ Index des pages<br/>pages_index.json]

        STATS_JSON[ğŸ“Š Statistiques corpus<br/>corpus_stats.json]

        IMAGE_MAPPING[ğŸ–¼ï¸ Correspondance images<br/>images_mapping.txt]

        EXPORT_START --> FORMAT_CHOICE
        FORMAT_CHOICE -->|clean| FORMAT_CLEAN
        FORMAT_CHOICE -->|diplomatic| FORMAT_DIPLO
        FORMAT_CHOICE -->|annotated| FORMAT_ANNOT

        FORMAT_CLEAN --> PAGE_SPLIT
        FORMAT_DIPLO --> PAGE_SPLIT
        FORMAT_ANNOT --> PAGE_SPLIT

        PAGE_SPLIT --> COMBINED_FILE
        PAGE_SPLIT --> INDEX_JSON
        PAGE_SPLIT --> STATS_JSON
        PAGE_SPLIT --> IMAGE_MAPPING
    end

    CORPUS_VERTICAL --> EXPORT_START

    %% SORTIE FINALE
    OUTPUT([ğŸ“¤ SORTIE MODULE 6<br/>Corpus enrichi + Fichiers exploitables])

    COMBINED_FILE --> OUTPUT
    INDEX_JSON --> OUTPUT
    STATS_JSON --> OUTPUT
    IMAGE_MAPPING --> OUTPUT

    %% ========================================
    %% ANNOTATIONS
    %% ========================================
    note1[ğŸ’¡ Configuration:<br/>config.yaml dÃ©finit<br/>tous les paramÃ¨tres<br/>du traitement]
    note2[ğŸ’¡ CLTK:<br/>PremiÃ¨re exÃ©cution lente<br/>TÃ©lÃ©chargement modÃ¨les<br/>Puis rapide]
    note3[ğŸ’¡ Formats:<br/>Clean = lecture humaine<br/>Diplomatic = semi-annotÃ©<br/>Annotated = analyse machine]
    note4[ğŸ’¡ MÃ©tadonnÃ©es:<br/>PrÃ©servÃ©es Ã  chaque Ã©tape<br/>TraÃ§abilitÃ© complÃ¨te]

    EXTRACT_START -.-> note1
    CLTK_PROCESS -.-> note2
    FORMAT_CHOICE -.-> note3
    INDEX_JSON -.-> note4

    %% ========================================
    %% STATISTIQUES
    %% ========================================
    subgraph STATS [ğŸ“Š CaractÃ©ristiques Techniques]
        S1[Langues supportÃ©es: Latin, FranÃ§ais]
        S2[Lemmatiseur: CLTK pour langues anciennes]
        S3[Formats sortie: 3 formats configurables]
        S4[MÃ©tadonnÃ©es: PrÃ©servÃ©es dans tous formats]
        S5[Performance: 100-1000 pages/minute]
    end

    %% ========================================
    %% OUTILS
    %% ========================================
    subgraph TOOLS [ğŸ› ï¸ Technologies UtilisÃ©es]
        T1[Python 3.10+]
        T2[CLTK: Classical Language Toolkit]
        T3[PyYAML: Configuration]
        T4[lxml: Manipulation XML]
        T5[JSON: Formats intermÃ©diaires]
    end

    %% ========================================
    %% STYLES
    %% ========================================
    classDef startEnd fill:#4caf50,stroke:#2e7d32,stroke-width:3px,color:#fff
    classDef decision fill:#ffeb3b,stroke:#f57f17,stroke-width:2px
    classDef extract fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    classDef enrich fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px
    classDef export fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef intermediate fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    classDef output fill:#a5d6a7,stroke:#2e7d32,stroke-width:3px
    classDef note fill:#fff9c4,stroke:#f57f17,stroke-width:1px,stroke-dasharray: 5 5

    class START,OUTPUT startEnd
    class COLUMN_DECISION,FORMAT_CHOICE decision
    class EXTRACT_START,SINGLE_COL,DUAL_COL,HYPHEN_MERGE extract
    class ENRICH_START,SENTENCE_SPLIT,TOKENIZATION,CLTK_PROCESS,VERTICAL_FORMAT enrich
    class EXPORT_START,FORMAT_CLEAN,FORMAT_DIPLO,FORMAT_ANNOT,PAGE_SPLIT export
    class JSON_INTERMEDIATE,CORPUS_VERTICAL intermediate
    class COMBINED_FILE,INDEX_JSON,STATS_JSON,IMAGE_MAPPING output
    class note1,note2,note3,note4 note

    style STEP1 fill:#e8f5e9,stroke:#1565c0,stroke-width:2px
    style STEP2 fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px
    style STEP3 fill:#fff8e1,stroke:#e65100,stroke-width:2px
    style STATS fill:#f5f5f5,stroke:#616161,stroke-width:2px,stroke-dasharray: 3 3
    style TOOLS fill:#e0f2f1,stroke:#00796b,stroke-width:2px,stroke-dasharray: 3 3
```

---

## ğŸ“š RÃ©fÃ©rences CroisÃ©es : Documentation â†” SchÃ©ma

### Ã‰tape 1 : Extraction

| Documentation (README.md) | SchÃ©ma Module 6 | Fichier Code |
|---------------------------|-----------------|--------------|
| Section "Ã‰tape 1 : Extraction des XML" (ligne 174-184) | Sous-graphe STEP1 | `step1_extract/` |
| Option `column_mode: single/dual` (ligne 106) | `COLUMN_DECISION` | `config.py` |
| Option `merge_hyphenated: true` (ligne 107) | `HYPHEN_MERGE` | `step1_extract/extractor.py` |
| Sortie `extracted.json` (ligne 184) | `JSON_INTERMEDIATE` | - |

### Ã‰tape 2 : Enrichissement

| Documentation (README.md) | SchÃ©ma Module 6 | Fichier Code |
|---------------------------|-----------------|--------------|
| Section "Ã‰tape 2 : Enrichissement" (ligne 186-198) | Sous-graphe STEP2 | `step2_enrich/` |
| Option `lemmatizer: cltk` (ligne 111) | `CLTK_PROCESS` | `config.py` |
| Option `language: lat` (ligne 112) | `CLTK_PROCESS` | `config.py` |
| Section "Format vertical" (ligne 251-289) | `VERTICAL_FORMAT` | - |
| Sortie `corpus.vertical.txt` (ligne 189) | `CORPUS_VERTICAL` | - |

### Ã‰tape 3 : Export

| Documentation (README.md) | SchÃ©ma Module 6 | Fichier Code |
|---------------------------|-----------------|--------------|
| Section "Ã‰tape 3 : Export" (ligne 200-210) | Sous-graphe STEP3 | `step3_export/` |
| Section "Formats de sortie" (ligne 213-248) | `FORMAT_CHOICE` | `config.py` |
| Format "clean" (ligne 215-221) | `FORMAT_CLEAN` | `step3_export/formatter.py` |
| Format "diplomatic" (ligne 223-229) | `FORMAT_DIPLO` | `step3_export/formatter.py` |
| Format "annotated" (ligne 231-241) | `FORMAT_ANNOT` | `step3_export/formatter.py` |
| Fichier `pages/page_*.txt` (ligne 161-163) | `PAGE_SPLIT` | - |
| Fichier `texte_complet.txt` (ligne 165) | `COMBINED_FILE` | - |
| Fichier `pages_index.json` (ligne 164) | `INDEX_JSON` | - |
| Fichier `corpus_stats.json` (ligne 166) | `STATS_JSON` | - |
| Fichier `images_mapping.txt` (ligne 167) | `IMAGE_MAPPING` | - |

---

## ğŸ”„ Flux de DonnÃ©es Complet : Module 5 â†’ PAGEtopage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODULE 5 : Nettoyage Post-eScriptorium                      â”‚
â”‚ (flowchart-module5.mmd)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [Import XML] â†’ [Stockage Seafile] â†’ [Export local]        â”‚
â”‚       â†“                                                     â”‚
â”‚  [Distinction Layout: 1/2/4 rÃ©gions Main]                   â”‚
â”‚       â†“                                                     â”‚
â”‚  [Application Regex Communes]                               â”‚
â”‚       â†“                                                     â”‚
â”‚  [Application Regex SpÃ©cifiques]                            â”‚
â”‚       â†“                                                     â”‚
â”‚  [VÃ©rification et Corrections]                              â”‚
â”‚       â†“                                                     â”‚
â”‚  âœ… SORTIE : Transcriptions XML PAGE finalisÃ©es            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                         â†“ (Fichiers XML PAGE nettoyÃ©s)
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODULE 6 : PAGEtopage - Enrichissement Linguistique        â”‚
â”‚ (PAGEtopage/)                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Ã‰TAPE 1 : Extraction                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  [Lecture XML PAGE] â†’ [Extraction texte]                   â”‚
â”‚       â†“                                                     â”‚
â”‚  [Gestion colonnes single/dual]                             â”‚
â”‚       â†“                                                     â”‚
â”‚  [Fusion mots coupÃ©s]                                       â”‚
â”‚       â†“                                                     â”‚
â”‚  â†’ extracted.json                                           â”‚
â”‚                                                             â”‚
â”‚  Ã‰TAPE 2 : Enrichissement                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  [Lecture JSON] â†’ [DÃ©coupage en phrases]                   â”‚
â”‚       â†“                                                     â”‚
â”‚  [Tokenisation]                                             â”‚
â”‚       â†“                                                     â”‚
â”‚  [Lemmatisation CLTK + POS-tagging]                        â”‚
â”‚       â†“                                                     â”‚
â”‚  â†’ corpus.vertical.txt                                      â”‚
â”‚                                                             â”‚
â”‚  Ã‰TAPE 3 : Export                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  [Lecture corpus vertical]                                  â”‚
â”‚       â†“                                                     â”‚
â”‚  [Choix format: clean/diplomatic/annotated]                â”‚
â”‚       â†“                                                     â”‚
â”‚  [GÃ©nÃ©ration fichiers par page]                            â”‚
â”‚       â†“                                                     â”‚
â”‚  âœ… SORTIES :                                               â”‚
â”‚     â€¢ pages/page_*.txt (un par page)                       â”‚
â”‚     â€¢ texte_complet.txt (tout le corpus)                   â”‚
â”‚     â€¢ pages_index.json (mÃ©tadonnÃ©es)                       â”‚
â”‚     â€¢ corpus_stats.json (statistiques)                     â”‚
â”‚     â€¢ images_mapping.txt (correspondances)                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                         â†“
                   CORPUS EXPLOITABLE
                (Analyse linguistique, recherches, etc.)
```

---

## ğŸ¯ Cas d'Usage : Du Manuscrit au Corpus AnnotÃ©

### Exemple Pratique

1. **MODULES 1-3** : Acquisition du manuscrit MS123 (DÃ©cret de Gratien, XIIe siÃ¨cle)
   - TÃ©lÃ©chargement IIIF depuis la British Library
   - 300 pages, TIF 600 DPI

2. **MODULE 4** : Traitement eScriptorium
   - Segmentation automatique (modÃ¨le rÃ©utilisÃ©)
   - Transcription HTR (CER = 5.2%)
   - Validation manuelle

3. **MODULE 5** : Nettoyage (`flowchart-module5.mmd`)
   - Import des 300 XML PAGE
   - DÃ©tection : 2 rÃ©gions Main par page (verso-recto)
   - Application regex communes (normalisation espaces)
   - Application regex spÃ©cifiques (abbrÃ©viations latines)
   - VÃ©rification : 12 erreurs dÃ©tectÃ©es et corrigÃ©es
   - **Sortie** : 300 fichiers XML PAGE finalisÃ©s

4. **MODULE 6** : PAGEtopage (`PAGEtopage/`)

   **Commande exÃ©cutÃ©e** :
   ```bash
   python -m PAGEtopage run \
       --input ./ms123_xml_pages/ \
       --output ./ms123_corpus/ \
       --config ms123_config.yaml
   ```

   **Ã‰tape 1 - Extraction** :
   - Lecture des 300 XML PAGE
   - Mode : `dual` (2 colonnes par page)
   - Fusion des mots coupÃ©s : 1847 occurrences
   - CrÃ©ation : `extracted.json` (2.3 Mo)

   **Ã‰tape 2 - Enrichissement** :
   - DÃ©coupage : 8 742 phrases
   - Tokenisation : 156 392 tokens
   - Lemmatisation CLTK (Latin) : 154 203 lemmes identifiÃ©s
   - POS-tagging : 97.8% de confiance
   - CrÃ©ation : `corpus.vertical.txt` (8.7 Mo)

   **Ã‰tape 3 - Export** :
   - Format choisi : `clean` (texte lisible)
   - GÃ©nÃ©ration de 300 fichiers `page_*.txt`
   - CrÃ©ation `texte_complet.txt` (512 Ko)
   - CrÃ©ation `pages_index.json` avec mÃ©tadonnÃ©es complÃ¨tes
   - Statistiques : 156k mots, 8.7k phrases, 300 pages

5. **RÃ‰SULTAT FINAL** : Corpus MS123 prÃªt pour :
   - Recherche plein-texte
   - Analyse linguistique (frÃ©quences, concordances)
   - Ã‰tudes lexicales (lemmes, POS)
   - Comparaison avec autres manuscrits
   - IntÃ©gration dans une base de donnÃ©es

---

## ğŸ”§ Fichiers de Configuration : Lien avec le SchÃ©ma

Le fichier `config.yaml` contrÃ´le chaque Ã©tape du schÃ©ma Module 6 :

```yaml
# ContrÃ´le COLUMN_DECISION dans Ã‰tape 1
extraction:
  column_mode: single          # â†’ SINGLE_COL
  # ou dual                    # â†’ DUAL_COL
  merge_hyphenated: true       # â†’ HYPHEN_MERGE

# ContrÃ´le CLTK_PROCESS dans Ã‰tape 2
enrichment:
  lemmatizer: cltk             # â†’ CLTK_PROCESS
  language: lat                # â†’ CLTK_PROCESS (Latin)

# ContrÃ´le FORMAT_CHOICE dans Ã‰tape 3
export:
  format: clean                # â†’ FORMAT_CLEAN
  # ou diplomatic              # â†’ FORMAT_DIPLO
  # ou annotated               # â†’ FORMAT_ANNOT
  generate_index: true         # â†’ INDEX_JSON
  generate_combined: true      # â†’ COMBINED_FILE
```

---

## ğŸ“– Exemples de DonnÃ©es Ã  Chaque Ã‰tape

### EntrÃ©e Module 6 (Sortie Module 5)

**Fichier** : `0042.xml` (XML PAGE finalisÃ©)

```xml
<?xml version="1.0" encoding="UTF-8"?>
<PcGts>
  <Page imageFilename="ms_0042.tif">
    <TextRegion id="region_main_1" type="MainZone">
      <TextLine id="line_1">
        <TextEquiv>
          <Unicode>Dominus enim dicit in evangelio</Unicode>
        </TextEquiv>
      </TextLine>
    </TextRegion>
  </Page>
</PcGts>
```

### AprÃ¨s Ã‰tape 1 (Extraction)

**Fichier** : `extracted.json`

```json
{
  "pages": [
    {
      "folio": "0042.xml",
      "page_number": 42,
      "text": "Dominus enim dicit in evangelio. Qui perseveraverit usque in finem, hic salvus erit."
    }
  ]
}
```

### AprÃ¨s Ã‰tape 2 (Enrichissement)

**Fichier** : `corpus.vertical.txt`

```
<doc folio="0042.xml" page_number="42" edition_id="MS123" title="DÃ©cret de Gratien">
<s>
Dominus	NOM	dominus
enim	ADV	enim
dicit	VER	dico
in	PRP	in
evangelio	NOM	evangelium
.	PUNCT	.
</s>
<s>
Qui	PRO	qui
perseveraverit	VER	persevero
usque	ADV	usque
in	PRP	in
finem	NOM	finis
,	PUNCT	,
hic	ADV	hic
salvus	ADJ	salvus
erit	VER	sum
.	PUNCT	.
</s>
</doc>
```

### AprÃ¨s Ã‰tape 3 (Export format "clean")

**Fichier** : `pages/page_0042_0042.txt`

```
Dominus enim dicit in evangelio. Qui perseveraverit usque in finem, hic salvus erit.
```

**Fichier** : `pages_index.json`

```json
{
  "pages": [
    {
      "folio": "0042.xml",
      "page_number": 42,
      "file_path": "pages/page_0042_0042.txt",
      "word_count": 15,
      "sentence_count": 2,
      "line_count": 1
    }
  ]
}
```

---

## ğŸš€ Utilisation Pratique : Commandes et SchÃ©ma

### Pipeline Complet (MÃ©thode RecommandÃ©e)

```bash
python -m PAGEtopage run \
    --input ./xml_pages/ \
    --output ./output/ \
    --config config.yaml
```

**Parcours dans le schÃ©ma** :
```
START â†’ INPUT_MODULE5 â†’ EXTRACT_START â†’ ... â†’ OUTPUT
```

### Pipeline Ã‰tape par Ã‰tape

#### Ã‰tape 1 : Extraction

```bash
python -m PAGEtopage extract \
    --input ./xml_pages/ \
    --output ./extracted.json
```

**Parcours** : `START â†’ STEP1 â†’ JSON_INTERMEDIATE`

#### Ã‰tape 2 : Enrichissement

```bash
python -m PAGEtopage enrich \
    --input ./extracted.json \
    --output ./corpus.vertical.txt
```

**Parcours** : `JSON_INTERMEDIATE â†’ STEP2 â†’ CORPUS_VERTICAL`

#### Ã‰tape 3 : Export

```bash
python -m PAGEtopage export \
    --input ./corpus.vertical.txt \
    --output ./pages/ \
    --format clean
```

**Parcours** : `CORPUS_VERTICAL â†’ STEP3 â†’ OUTPUT`

---

## ğŸ“Š Mise Ã  Jour de l'Index des SchÃ©mas

### Ajout RecommandÃ© Ã  `Shema_module_projet/FLOWCHARTS_INDEX.md`

Ajouter une nouvelle section aprÃ¨s le MODULE 5 :

```markdown
#### ğŸ“Œ [flowchart-module6-pagetopage.mmd](./flowchart-module6-pagetopage.mmd)
**MODULE 6 - Enrichissement Linguistique (PAGEtopage)**
**Niveau de dÃ©tail:** â­â­â­â­ (TrÃ¨s dÃ©taillÃ©)

**Contenu:**
- Ã‰tape 1 : Extraction du texte depuis XML PAGE
  - Gestion des colonnes (single/dual)
  - Fusion des mots coupÃ©s
  - Production JSON intermÃ©diaire
- Ã‰tape 2 : Enrichissement linguistique
  - DÃ©coupage en phrases et tokenisation
  - Lemmatisation CLTK (langues anciennes)
  - POS-tagging automatique
  - Production format vertical
- Ã‰tape 3 : Export multi-formats
  - Format clean (texte brut)
  - Format diplomatic (annotations inline)
  - Format annotated (tabulaire)
  - GÃ©nÃ©ration index et statistiques
- Technologies : Python, CLTK, PyYAML, lxml

**IdÃ©al pour:**
- Comprendre la transformation XML â†’ Corpus annotÃ©
- Planifier l'enrichissement linguistique
- Choisir les formats de sortie appropriÃ©s

**Code source:** `../PAGEtopage/`
**Documentation:** `../PAGEtopage/README.md`
```

---

## ğŸ“ Glossaire Ã‰tendu : Termes du Module 6

| Terme | DÃ©finition | RÃ©fÃ©rence SchÃ©ma |
|-------|------------|------------------|
| **Format Vertical** | Format d'annotation linguistique avec un mot par ligne, incluant lemme et POS | `VERTICAL_FORMAT` |
| **Lemmatisation** | RÃ©duction d'un mot Ã  sa forme canonique (dicit â†’ dico) | `CLTK_PROCESS` |
| **POS-tagging** | Part-of-Speech tagging, Ã©tiquetage grammatical (nom, verbe...) | `CLTK_PROCESS` |
| **CLTK** | Classical Language Toolkit, bibliothÃ¨que Python pour langues anciennes | `CLTK_PROCESS` |
| **Tokenisation** | DÃ©coupage du texte en unitÃ©s (mots, ponctuation) | `TOKENIZATION` |
| **Format Clean** | Texte brut sans annotations, lisible par humains | `FORMAT_CLEAN` |
| **Format Diplomatic** | Texte avec annotations entre parenthÃ¨ses | `FORMAT_DIPLO` |
| **Format Annotated** | Format tabulaire avec colonnes (mot/POS/lemme) | `FORMAT_ANNOT` |
| **Mots coupÃ©s** | Mots sÃ©parÃ©s par un tiret en fin de ligne (re-/constituer) | `HYPHEN_MERGE` |
| **JSON intermÃ©diaire** | Format temporaire entre extraction et enrichissement | `JSON_INTERMEDIATE` |
| **Corpus vertical** | Fichier contenant tout le corpus au format vertical | `CORPUS_VERTICAL` |

---

## ğŸ”— Ressources et Liens

### Documentation

- **PAGEtopage README** : `PAGEtopage/README.md`
- **PAGEtopage QUICKSTART** : `PAGEtopage/QUICKSTART.md`
- **SchÃ©ma Module 5** : `Shema_module_projet/flowchart-module5.mmd`
- **Index des SchÃ©mas** : `Shema_module_projet/FLOWCHARTS_INDEX.md`

### Code Source

- **Ã‰tape 1** : `PAGEtopage/step1_extract/`
- **Ã‰tape 2** : `PAGEtopage/step2_enrich/`
- **Ã‰tape 3** : `PAGEtopage/step3_export/`
- **Configuration** : `PAGEtopage/config.py`
- **CLI** : `PAGEtopage/cli.py`
- **ModÃ¨les** : `PAGEtopage/models.py`

### Outils Externes

- **CLTK** : https://cltk.org/
- **PageXML** : https://github.com/PRImA-Research-Lab/PAGE-XML
- **PyYAML** : https://pyyaml.org/
- **lxml** : https://lxml.de/

---

## ğŸ“ Conclusion

Ce document Ã©tablit le **lien conceptuel et technique** entre :

1. **Le schÃ©ma existant Module 5** (`flowchart-module5.mmd`) qui dÃ©crit le nettoyage post-eScriptorium
2. **Le nouveau dossier PAGEtopage** qui Ã©tend le pipeline avec l'enrichissement linguistique

**PAGEtopage** doit Ãªtre considÃ©rÃ© comme un **Module 6** Ã  part entiÃ¨re, transformant les transcriptions XML PAGE finalisÃ©es en **corpus annotÃ©s linguistiquement exploitables**.

Le schÃ©ma Mermaid proposÃ© dans ce document peut Ãªtre sauvegardÃ© comme `flowchart-module6-pagetopage.mmd` dans le dossier `Shema_module_projet/` pour complÃ©ter la documentation visuelle du pipeline.

---

**DerniÃ¨re mise Ã  jour** : DÃ©cembre 2024
**Auteur** : Ã‰quipe Data_Base
**Version** : 1.0
